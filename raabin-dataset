import os
import torch
import timm
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report
)
import numpy as np

# -----------------------------
# CONFIG
# -----------------------------
DATASET_ROOT = "/lapix/dataset_raabin"
MODEL_WEIGHTS = "vit_base_multilabel_best.pth"   # your original
OUTPUT_MODEL = "vit_raabin_finetuned.pth"

BATCH_SIZE = 16
EPOCHS = 10
LR = 1e-4
IMG_SIZE = 384
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"


# -----------------------------
# DATA TRANSFORMS
# -----------------------------
transform_train = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor(),
])

transform_val = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
])

train_dataset = datasets.ImageFolder(os.path.join(DATASET_ROOT, "Train"), transform=transform_train)
val_dataset   = datasets.ImageFolder(os.path.join(DATASET_ROOT, "Test-A"), transform=transform_val)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

num_classes = len(train_dataset.classes)
print("Classes:", train_dataset.classes)


# -----------------------------
# MODEL
# -----------------------------
# load ViT Base 384 pre-trained architecture
model = timm.create_model("vit_base_patch16_384", pretrained=False, num_classes=0)

# load your original state dict (multi-label model)
state = torch.load(MODEL_WEIGHTS, map_location="cpu")
model.load_state_dict(state, strict=False)

# create new classification head for RAABIN (5 classes)
in_features = model.num_features   # = 768 for ViT-Base 384
model.head = nn.Linear(in_features, num_classes)

model = model.to(DEVICE)
optimizer = torch.optim.Adam(model.parameters(), lr=LR)
criterion = nn.CrossEntropyLoss()


# -----------------------------
# TRAIN + METRICS
# -----------------------------
def evaluate_metrics(model, loader):
    model.eval()
    preds, labels = [], []

    with torch.no_grad():
        for imgs, lbls in loader:
            imgs, lbls = imgs.to(DEVICE), lbls.to(DEVICE)
            outputs = model(imgs)
            batch_preds = torch.argmax(outputs, dim=1)

            preds.extend(batch_preds.cpu().numpy())
            labels.extend(lbls.cpu().numpy())

    preds = np.array(preds)
    labels = np.array(labels)

    acc = accuracy_score(labels, preds)
    prec_macro = precision_score(labels, preds, average='macro', zero_division=0)
    recall_macro = recall_score(labels, preds, average='macro', zero_division=0)
    f1_macro = f1_score(labels, preds, average='macro', zero_division=0)
    f1_weighted = f1_score(labels, preds, average='weighted', zero_division=0)
    cm = confusion_matrix(labels, preds)

    return acc, prec_macro, recall_macro, f1_macro, f1_weighted, cm, labels, preds


# -----------------------------
# TRAINING LOOP
# -----------------------------
for epoch in range(1, EPOCHS + 1):
    model.train()
    running_loss = 0.0

    for imgs, lbls in train_loader:
        imgs, lbls = imgs.to(DEVICE), lbls.to(DEVICE)

        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, lbls)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    # eval metrics
    acc, prec, rec, f1_macro, f1_weighted, cm, labels_out, preds_out = evaluate_metrics(model, val_loader)

    print(f"\nEpoch {epoch}/{EPOCHS}")
    print(f"  Train Loss: {running_loss / len(train_loader):.4f}")
    print(f"  Val Acc:    {acc:.4f}")
    print(f"  Precision:  {prec:.4f}")
    print(f"  Recall:     {rec:.4f}")
    print(f"  F1 Macro:   {f1_macro:.4f}")
    print(f"  F1 Weighted:{f1_weighted:.4f}")
    print("------------------------------------")

# save model
torch.save(model.state_dict(), OUTPUT_MODEL)
print("Saved:", OUTPUT_MODEL)

# -----------------------------
# PRINT FULL REPORT
# -----------------------------
print("\n=== FULL CLASSIFICATION REPORT ===")
print(classification_report(labels_out, preds_out, target_names=train_dataset.classes))

print("\n=== CONFUSION MATRIX ===")
print(cm)
